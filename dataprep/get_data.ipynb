{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb1d516",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "home_locations_df = pd.read_csv('./data/home_locations.csv')\n",
    "\n",
    "# Get a list of all country codes from the 'country' column\n",
    "country_codes = home_locations_df['COUNTRY'].unique().tolist()\n",
    "\n",
    "print(country_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d411bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the stations file with error handling for inconsistent fields\n",
    "stations_df = pd.read_csv('data/ghcnd-stations.csv', on_bad_lines='skip', engine='python')\n",
    "\n",
    "# Filter stations that have IDs starting with any of the country codes\n",
    "home_stations_df = stations_df[stations_df['ID'].str[:2].isin(country_codes)]\n",
    "\n",
    "# Write the filtered data to a new CSV file\n",
    "home_stations_df.to_csv('data/home_stations.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c00e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.distance import geodesic\n",
    "\n",
    "# Create an empty list to store the results\n",
    "nearby_stations = []\n",
    "\n",
    "# Iterate through each home location\n",
    "for idx, home_row in home_locations_df.iterrows():\n",
    "    home_coords = (home_row['LATITUDE'], home_row['LONGITUDE'])\n",
    "    city = home_row['CITY']\n",
    "    \n",
    "    # Check each station in home_stations_df\n",
    "    for station_idx, station_row in home_stations_df.iterrows():\n",
    "        # Only calculate distance if station country matches home location country\n",
    "        if station_row['ID'][:2] == home_row['COUNTRY']:\n",
    "            station_coords = (station_row['LATITUDE'], station_row['LONGITUDE'])\n",
    "            \n",
    "            # Calculate distance in kilometers\n",
    "            distance = geodesic(home_coords, station_coords).kilometers\n",
    "            \n",
    "            # Set distance threshold based on city\n",
    "            distance_threshold = 30 if city == 'London' else 20\n",
    "            \n",
    "            # If within threshold, add to results\n",
    "            if distance <= distance_threshold:\n",
    "            # Create a copy of the station row and add the CITY column\n",
    "                station_data = station_row.to_dict()\n",
    "                station_data['CITY'] = city\n",
    "                nearby_stations.append(station_data)\n",
    "\n",
    "# Create the new dataframe\n",
    "nearby_stations_df = pd.DataFrame(nearby_stations)\n",
    "\n",
    "print(f\"Found {len(nearby_stations_df)} stations within 20km of home locations\")\n",
    "print(nearby_stations_df.head())\n",
    "nearby_stations_df.to_csv('data/nearby_stations.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba28d15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ftplib\n",
    "import gzip\n",
    "import os\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "os.makedirs('data/by_station', exist_ok=True)\n",
    "# Read the nearby stations CSV file\n",
    "nearby_stations_df = pd.read_csv('data/nearby_stations.csv')\n",
    "# Connect to the FTP server\n",
    "ftp = ftplib.FTP('ftp.ncei.noaa.gov')\n",
    "ftp.login()  # Anonymous login\n",
    "\n",
    "# Change to the target directory\n",
    "ftp.cwd('pub/data/ghcn/daily/by_station')\n",
    "\n",
    "# Download and process files for each station\n",
    "for idx, row in nearby_stations_df.iterrows():\n",
    "    station_id = row['ID']\n",
    "    print(f\"Processing station: {station_id}\")\n",
    "    filename = f\"{station_id}.csv.gz\"\n",
    "    local_gz_path = f\"data/by_station/{filename}\"\n",
    "    local_csv_path = f\"data/by_station/{station_id}.csv\"\n",
    "    \n",
    "    # Skip if file already exists\n",
    "    if os.path.exists(local_csv_path):\n",
    "        print(f\"Skipping {station_id}.csv (already exists)\")\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        # Download the .csv.gz file\n",
    "        with open(local_gz_path, 'wb') as f:\n",
    "            ftp.retrbinary(f'RETR {filename}', f.write)\n",
    "        \n",
    "        # Decompress the .gz file\n",
    "        with gzip.open(local_gz_path, 'rb') as f_in:\n",
    "            with open(local_csv_path, 'wb') as f_out:\n",
    "                f_out.write(f_in.read())\n",
    "        \n",
    "        # Remove the .gz file after extraction\n",
    "        os.remove(local_gz_path)\n",
    "        \n",
    "        print(f\"Downloaded and extracted: {station_id}.csv\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading {filename}: {e}\")\n",
    "\n",
    "# Close the FTP connection\n",
    "ftp.quit()\n",
    "\n",
    "print(f\"\\nCompleted downloading {len(nearby_stations_df)} station files\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataprep-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
